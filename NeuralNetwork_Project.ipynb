{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx69M3uu5jmI",
        "colab_type": "text"
      },
      "source": [
        "Importing necessary Libraries for dataframes and for classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_omZG1twUNO",
        "colab_type": "code",
        "outputId": "d6071566-1e4f-4f5f-f028-6781021f3fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib.request\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import layers\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CaqyHyO5p9T",
        "colab_type": "text"
      },
      "source": [
        "Declaring the column header"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en350X_5Olvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = np.array(['Attr1', 'Attr2', 'Attr3', 'Attr4', 'Attr5', 'Attr6', 'Attr7', 'Attr8',\n",
        "       'Attr9', 'Attr10', 'Attr11', 'Attr12', 'Attr13', 'Attr14', 'Attr15',\n",
        "       'Attr16', 'Attr17', 'Attr18', 'Attr19', 'Attr20', 'Attr21', 'Attr22',\n",
        "       'Attr23', 'Attr24', 'Attr25', 'Attr26', 'Attr27', 'Attr28', 'Attr29',\n",
        "       'Attr30', 'Attr31', 'Attr32', 'Attr33', 'Attr34', 'Attr35', 'Attr36',\n",
        "       'Attr37', 'Attr38', 'Attr39', 'Attr40', 'Attr41', 'Attr42', 'Attr43',\n",
        "       'Attr44', 'Attr45', 'Attr46', 'Attr47', 'Attr48', 'Attr49', 'Attr50',\n",
        "       'Attr51', 'Attr52', 'Attr53', 'Attr54', 'Attr55', 'Attr56', 'Attr57',\n",
        "       'Attr58', 'Attr59', 'Attr60', 'Attr61', 'Attr62', 'Attr63', 'Attr64',\n",
        "       'class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdRYa7MQQnN3",
        "colab_type": "text"
      },
      "source": [
        "1.This function fetches the data from given URL. Then convert the string into list and then to dataframes\n",
        "\n",
        "2.This will return the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXEXhjJ6_edy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_fetching(url):\n",
        "  data = urllib.request.urlopen(url).read().decode('utf-8')\n",
        "  data=data.replace('?','0')\n",
        "  data_split = data.split('\\n')\n",
        "  data_split1 = data_split[70:]\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  del data_split1[-1]\n",
        "  del data_split1[-1]\n",
        "  del data_split1[-1]\n",
        "  for i in data_split1:\n",
        "    j = i.split(',')\n",
        "    j=[float(x) for x in j]    \n",
        "    m = pd.DataFrame(j,).T\n",
        "    df = df.append(m,ignore_index=True)\n",
        "  return df\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiC9rY30RABd",
        "colab_type": "text"
      },
      "source": [
        "We are fetching dataframes for each year using the function described above by passing the URL of each year dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0gQNPBPQIFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url1 = \"https://raw.githubusercontent.com/pragnabodipudi1/NeuralNetworks/master/1year.arff\"\n",
        "df1 = data_fetching(url1)\n",
        "url2 = \"https://raw.githubusercontent.com/pragnabodipudi1/NeuralNetworks/master/2year.arff\"\n",
        "df2 = data_fetching(url2)\n",
        "url3 = \"https://raw.githubusercontent.com/pragnabodipudi1/NeuralNetworks/master/3year.arff\"\n",
        "df3 = data_fetching(url3)\n",
        "url4 = \"https://raw.githubusercontent.com/pragnabodipudi1/NeuralNetworks/master/4year.arff\"\n",
        "df4 = data_fetching(url4)\n",
        "url5 = \"https://raw.githubusercontent.com/pragnabodipudi1/NeuralNetworks/master/5year.arff\"\n",
        "df5 = data_fetching(url5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEvhbMZ9RWwx",
        "colab_type": "text"
      },
      "source": [
        "We are appending the the different frames(fetched for each year) into single frame\n",
        "\n",
        "We are also giving the name to columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRFoa0NKoy5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = pd.DataFrame()\n",
        "df_final=df_final.append(df1,ignore_index=True)\n",
        "df_final=df_final.append(df2,ignore_index=True)\n",
        "df_final=df_final.append(df2,ignore_index=True)\n",
        "df_final=df_final.append(df4,ignore_index=True)\n",
        "df_final=df_final.append(df5,ignore_index=True)\n",
        "\n",
        "\n",
        "df_final.columns=col\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGi9C_7TSFVU",
        "colab_type": "text"
      },
      "source": [
        "There are so many missing values or zeros across the dataframe. Trying to count no of missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtIGlWpjtZzD",
        "colab_type": "code",
        "outputId": "7aa1b129-8634-444d-8ad9-917e5e596474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df = df_final\n",
        "df = df.drop(columns=['class'])\n",
        "df = df.where(df>0)\n",
        "df.isnull().sum().sort_values(ascending=False).head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attr6     27324\n",
              "Attr5     22081\n",
              "Attr59    20056\n",
              "Attr37    18791\n",
              "Attr48    18050\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyBY2ikTDAJ",
        "colab_type": "text"
      },
      "source": [
        "Dropping the columns with most missed values from dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fC36nnKUro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final=df_final.drop(columns=['Attr6','Attr5','Attr59','Attr37','Attr48'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHT2zc4ETK4l",
        "colab_type": "text"
      },
      "source": [
        "Replacing the available zeros with mean values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga4wSNChLBmq",
        "colab_type": "code",
        "outputId": "727dc4ea-7b0d-4c84-9998-325c8c2eddb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df_final.fillna(df.mean(),inplace=True)\n",
        "print(df_final.shape)\n",
        "X = df.iloc[:, [0, 59]]\n",
        "y = df.iloc[:, 59]\n",
        "df = df_final\n",
        "print(df.head(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43060, 60)\n",
            "      Attr1     Attr2     Attr3    Attr4  ...    Attr62   Attr63    Attr64  class\n",
            "0  0.209120  0.499880  0.472250   1.9447  ...  107.3500   3.4000   60.9870    0.0\n",
            "1  0.248660  0.695920  0.267130   1.5548  ...  134.2700   2.7185    5.2078    0.0\n",
            "2  0.081483  0.307340  0.458790   2.4928  ...   86.4350   4.2228    5.5497    0.0\n",
            "3  0.187320  0.613230  0.229600   1.4063  ...  127.2100   2.8692    7.8980    0.0\n",
            "4  0.228220  0.497940  0.359690   1.7502  ...   88.4440   4.1269   12.2990    0.0\n",
            "5  0.111090  0.647440  0.289710   1.4705  ...  129.5500   2.8173   18.3520    0.0\n",
            "6  0.532320  0.027059  0.705540  53.9540  ...    7.4503  48.9910    2.3217    0.0\n",
            "7  0.009020  0.632020  0.053735   1.1263  ...  116.5000   3.1330    2.5603    0.0\n",
            "8  0.124080  0.838370  0.142040   1.1694  ...  144.6300   2.5236  107.6700    0.0\n",
            "9  0.240010  0.443550  0.188350   1.4400  ...   32.9280  11.0850   12.3690    0.0\n",
            "\n",
            "[10 rows x 60 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHDKakJu5trL",
        "colab_type": "text"
      },
      "source": [
        " Here data is imbalanced.Classification using class-imbalanced data is biased in favor of the majority class. The bias is even larger for high-dimensional data, where the number of variables greatly exceeds the number of samples.There are so many techniques to overcome the problem. Popular among them is SMOTE(Synthetic Minority Oversampling Technique).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpDae0kVwglt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('class', axis=1)\n",
        "y = np.array(df['class'].tolist()) \n",
        "#smote\n",
        "smote = SMOTE(ratio='auto' , random_state=42, k_neighbors=10)\n",
        "dfi_features_res, dfi_label_res = smote.fit_sample(X, y)\n",
        "print(dfi_features_res.shape)\n",
        "print(dfi_label_res.shape)\n",
        "count_0 =0\n",
        "count_1=0\n",
        "for c in dfi_label_res:\n",
        "  if(c == 0):\n",
        "    count_0= count_0+1\n",
        "  else:\n",
        "    count_1 = count_1+1\n",
        "print(\"count_1\",count_1)\n",
        "print(\"count_0\",count_0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55iraYIwV3Om",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ3_ZTiX5w8O",
        "colab_type": "text"
      },
      "source": [
        "Here we are using different classifies to validate the data.\n",
        "We are declaring different classifiers\n",
        "\n",
        "1.Gaussian Naïve Bayes, 2.Adaptive Boosting, 3.Logistc Regression 4. Random forest classifier 5.neural network 6. k-nearest neighbors algorithm 7.Decision Tree Classifier 8. X gradient boosting   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbVntzInwh4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hussy\n",
        "gnb_classifier = GaussianNB()\n",
        "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=200)\n",
        "#Rakshith\n",
        "lr_classifier = LogisticRegression(penalty = 'l1', random_state = 0)\n",
        "rfc = RandomForestClassifier()\n",
        "#Pragna\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "xgb_classifier = XGBClassifier()\n",
        "#Sai Vinay\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=1,n_jobs=1)\n",
        "#Deep Neural Network implemented at the bottom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3TaChPC51Y6",
        "colab_type": "text"
      },
      "source": [
        "This function is used to implement k-Fold Cross-Validating Neural Networks\n",
        "\n",
        "To train a classifier network\n",
        "\n",
        "To display training and testing results\n",
        "\n",
        "to display convolution matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX_UrEv1wlCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold(classifier12):\n",
        "  scores=[]\n",
        "  #dfi_features_res, dfi_label_res\n",
        "  kf = KFold(n_splits=10, shuffle=False, random_state=42)\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  X_test = []\n",
        "  y_test = []\n",
        "  for train_index, test_index in kf.split(dfi_features_res):\n",
        "    X_train, X_test, y_train, y_test = dfi_features_res[train_index], dfi_features_res[test_index], dfi_label_res[train_index], dfi_label_res[test_index]  \n",
        "    classifier12.fit(X_train, y_train)\n",
        "    scores.append(classifier12.score(X_test, y_test))\n",
        "    print(scores)\n",
        " \n",
        "  print(np.mean(scores))\n",
        "  \n",
        "  y_pred=cross_val_predict(classifier12, dfi_features_res, dfi_label_res, cv=kf)\n",
        "  accuracy = accuracy_score(y_pred.astype(int), dfi_label_res.astype(int))\n",
        "  print(accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ozhrk46BqQ",
        "colab_type": "text"
      },
      "source": [
        "To train a classifier network without k-fold\n",
        "\n",
        "To display training and testing results\n",
        "\n",
        "to display convolution matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Xcu7z1wotK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With out kfold\n",
        "def WithOut_KFold(classifier12):\n",
        "  X_train_S, X_test_S, y_train_S, y_test_S = train_test_split(dfi_features_res, dfi_label_res,random_state=1)\n",
        "  classifier12.fit(X_train_S,y_train_S)\n",
        "  predictions = classifier12.predict(X_test_S)\n",
        "  confusion_matrix(y_test_S, predictions)\n",
        "  print(classification_report(y_test_S, predictions))\n",
        "  confusion_matrix(y_test_S, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R109zDW3a5wf",
        "colab_type": "text"
      },
      "source": [
        "Showing results for X gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8FFexmBafjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(xgb_classifier)\n",
        "WithOut_KFold(xgb_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MibL50s-dL5K",
        "colab_type": "text"
      },
      "source": [
        "Showing results for Decision Tree Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOi_XjEs9vrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(dt_classifier)\n",
        "WithOut_KFold(dt_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ-vw3826HTz",
        "colab_type": "text"
      },
      "source": [
        "Showing results for Gaussian Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxJqisaRxpZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(gnb_classifier)\n",
        "WithOut_KFold(gnb_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAYZd49Ab15j",
        "colab_type": "text"
      },
      "source": [
        " Showing results for Adaptive Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xwaJgRzb08W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(ada_boost)\n",
        "WithOut_KFold(ada_boost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CUd3_Pva1Ti",
        "colab_type": "text"
      },
      "source": [
        "Showing results for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCD2xKH-aZg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(lr_classifier)\n",
        "WithOut_KFold(lr_classifier)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Urva01cQal",
        "colab_type": "text"
      },
      "source": [
        "Showing results for Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSz0uXdWcPqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold(rf_classifier)\n",
        "WithOut_KFold(rf_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m5ChGintwig",
        "colab_type": "text"
      },
      "source": [
        "Showing results for KNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9S9KjHZtvmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dfi_features_res, dfi_label_res,random_state=1)\n",
        "\n",
        "#Measuring the Accuracy of the model by taking different values of k.\n",
        "k_range = (1,26)\n",
        "scores={}\n",
        "scores_list=[]\n",
        "\n",
        "for k in k_range:\n",
        "  knn = KNeighborsClassifier(n_neighbors= k ) \n",
        "  knn.fit(X_train, y_train)\n",
        "  y_pred = knn.predict(X_test)\n",
        "  scores[k] = metrics.accuracy_score(y_test, y_pred)\n",
        "  scores_list.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#Plotting the Accuracy of the odel for each k which we have computed above.\n",
        "plt.plot(k_range, scores_list)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Testing Accuracy')\n",
        "\n",
        "#We have finally fixed our k as 1 and fit our data into it.\n",
        "classifier = KNeighborsClassifier(n_neighbors=1,n_jobs=1)  \n",
        "classifier.fit(X_train, y_train)\n",
        "target_predict = classifier.predict(X_test)\n",
        "\n",
        "#Printing the Confusion matrix and Test Accuracy of the Model.\n",
        "print(confusion_matrix(y_test, target_predict))\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, target_predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZQNFBucuu3M",
        "colab_type": "text"
      },
      "source": [
        "Showing results for Deep Learning Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTGwDW9Cu2Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Coverting our class labels into one hot encoding\n",
        "dfi_label_res = to_categorical(dfi_label_res)\n",
        "\n",
        "#Splitting the dataset into training and testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(dfi_features_res, dfi_label_res,random_state=1)\n",
        "\n",
        "#Assigning our model as Sequential\n",
        "model=Sequential()\n",
        "\n",
        "#Adding a dense hidden layer to our network with input dim as number of columns\n",
        "#Relu is used as an Activation function\n",
        "model.add(Dense(X_train.shape[0],input_dim=X_train.shape[1],activation='relu'))\n",
        "#Dropout technique is used to prevent overfitting of the data \n",
        "model.add(layers.Dropout(0.3))\n",
        "#Added some more hidden layers\n",
        "model.add(Dense(40,activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "#Compiled our model using loss and optimizer functions.\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "#Finally our model is fit using our training dataset\n",
        "model.fit(X_train,y_train,epochs=5,batch_size=800,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki74mzHJvktB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assigning our test results to a variable\n",
        "predictions =  model.predict(X_test)\n",
        "\n",
        "print(\"Predictions in one hot encoding :\",predictions)\n",
        "print(\"Displaying our test labels :\",y_test)\n",
        "\n",
        "#De-coding our one hot encoding into integers.\n",
        "predictions = np.argmax(predictions, axis= 1)\n",
        "\n",
        "#Displaying the Training and Testing Accuracy of our model\n",
        "print(\"Train Accuracy: \", model.evaluate(X_train, y_train, verbose=2)[1])\n",
        "print(\"Test Accuracy: \", model.evaluate(X_test,  y_test, verbose=2)[1])\n",
        "\n",
        "#Converting our testing labels into integers from one hot encoding.\n",
        "y_test= np.argmax(y_test, axis= 1)\n",
        "\n",
        "print(\"Confusion Matrix :\",(confusion_matrix(y_test, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}